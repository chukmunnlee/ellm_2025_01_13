{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Large Language Model - Prompts\n",
    "\n",
    "In this workshop, you will learn how to fine tune the prompts and the LLMs to enhance and improves its response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring the dataset\n",
    "\n",
    "In this workshop we will be using [<code>knkarthick/dialogsum</code>](https://huggingface.co/datasets/knkarthick/dialogsum) dataset from [HuggingFace](https://huggingface.co/). The dataset contains manually labelled summary and topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 12460\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "})\n",
      "{'train': (12460, 4), 'validation': (500, 4), 'test': (1500, 4)}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load and explore the following datasets\n",
    "# Q: Number of sets? \n",
    "# Q: How many records in each of these sets?\n",
    "# Q: What are the column names?\n",
    "\n",
    "dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "print(dataset)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "train_100\n",
      "\n",
      "DIALOGUE\n",
      "#Person1#: I have a problem with my cable.\n",
      "#Person2#: What about it?\n",
      "#Person1#: My cable has been out for the past week or so.\n",
      "#Person2#: The cable is down right now. I am very sorry.\n",
      "#Person1#: When will it be working again?\n",
      "#Person2#: It should be back on in the next couple of days.\n",
      "#Person1#: Do I still have to pay for the cable?\n",
      "#Person2#: We're going to give you a credit while the cable is down.\n",
      "#Person1#: So, I don't have to pay for it?\n",
      "#Person2#: No, not until your cable comes back on.\n",
      "#Person1#: Okay, thanks for everything.\n",
      "#Person2#: You're welcome, and I apologize for the inconvenience.\n",
      "\n",
      "SUMMARY\n",
      "#Person1# has a problem with the cable. #Person2# promises it should work again and #Person1# doesn't have to pay while it's down.\n",
      "\n",
      "TOPIC\n",
      "cable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 100 \n",
    "\n",
    "for k, v in dataset['train'][idx].items():\n",
    "   print(f'{k.upper()}\\n{v}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to summarize the dialogue from the training dataset. Use the google/flan-t5-base LLM.  \n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot prompt\n",
    "\n",
    "A instruction prompt for the LLM to perform a task without having seen any examples. \n",
    "\n",
    "Characteristics of zero-shot prompts include\n",
    "- <b>No provided examples</b> The prompt does not include any explicit examples of the desired input or output\n",
    "- <b>Direct instruction</b> The prompt describes what is expected of the LLM\n",
    "- <b>Relies on pre-training</b> Relies only on the data that the LLM is trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a Zero-Shot prompt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a Zero Shot prompt using Flan prompt template\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One and Few Short Prompt\n",
    "\n",
    "Refers to the prompting technique where the model is given 1 example of the task. The example is used to help the LLM to understand the task's requirements and to generate appropriate response.\n",
    "\n",
    "Characteristics of a one-shot prompt include\n",
    "- <b>Single example</b> - The prompt includes a single input/output pair example\n",
    "- <b>Instruction and query</b> - The provided example will be followed by a query that the LLM needs to respond to in the same format as the example\n",
    "- <b>Task guidance</b> - The example serves to guide the LLM to give the desired response\n",
    "\n",
    "FLAN uses the following template format for one/few shot prompts\n",
    "```\n",
    "<input_prefix>\n",
    "{example_0_inputs}\n",
    "\\n\\n\n",
    "<target_prefix>\n",
    "{example_0_targets}\n",
    "\\n\\n\\n\n",
    "<input_prefix>\n",
    "{example_1_inputs}\n",
    "\\n\\n\n",
    "<target_prefix>\n",
    "{example_1_targets}\n",
    "\\n\\n\\n\n",
    "<input_prefix>\n",
    "{actual_inputs}\n",
    "\\n\\n\n",
    "<target_prefix>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create examplars\n",
    "def mk_examplars(dataset, idxs):\n",
    "   prompt = \"\"\n",
    "   for _, i in enumerate(idxs):\n",
    "      dialogue = dataset[i]['dialogue']\n",
    "      summary = dataset[i]['summary']\n",
    "      #summary = dataset['train'][i]['topic']\n",
    "      prompt += f\"Summarize this article:\\n\\n{dialogue}\\n\\nSummary:\\n{summary}\\n\\n\\n\"\n",
    "   return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize this article:\n",
      "\n",
      "#Person1#: I am tired of everything in my life.\n",
      "#Person2#: What? How happy you life is! I do envy you.\n",
      "#Person1#: You don't know that I have been over-protected by my mother these years. I am really about to leave the family and spread my wings.\n",
      "#Person2#: Maybe you are right.\n",
      "\n",
      "Summary:\n",
      "#Person1# feels tired because of #Person1#'s mother's over-protection.\n",
      "\n",
      "\n",
      "Summarize this article:\n",
      "\n",
      "#Person1#: Did you know that drinking beer helps you sing better?\n",
      "#Person2#: Are you sure? How do you know?\n",
      "#Person1#: Well, usually people think I'm a terrible singer, but after we all have a few beers, they say I sound a lot better!\n",
      "#Person2#: Well, I heard that if you drink enough beer, you can speak foreign languages better. . .\n",
      "#Person1#: Then after a few beers, you'll be singing in Taiwanese?\n",
      "#Person2#: Maybe. . .\n",
      "\n",
      "Summary:\n",
      "#Person1# says drinking beer helps sing better, but #Person2# heard it helps speaking foreign languages.\n",
      "\n",
      "\n",
      "Summarize this article:\n",
      "\n",
      "#Person1#: We've been cramming for tomorrow's history exam since early this morning. What do you say we take a break and listen to some music, okay?\n",
      "#Person2#: Now that you mention it, I'm getting a little bumed-out from studying nonstop, too. Listening to some music for a while would suit me just fine.\n",
      "#Person1#: While you're picking out a record to play, I'll grab a couple of beers out of the refrigerator.\n",
      "#Person2#: You sure have a lot of discs here.\n",
      "#Person1#: Yeah, I've got everything from rock n'roll to the latest new - wave stuff.\n",
      "#Person2#: To tell you the truth, I'm strictly into classical music. You don't happen to have any Bach or Mozart, do you?\n",
      "#Person1#: Sorry, my taste in music doesn't go back any further than the 1960's. Music written before then is just history to me.\n",
      "#Person2#: Well, speaking of history, let's get back to the books. We'Ve got an exam tomorrow, remember?\n",
      "\n",
      "Summary:\n",
      "#Person1# and #Person2# are preparing for the history exam. #Person1# suggests taking a break to listen to some music, but they have different music tastes. Then they get back to books.\n",
      "\n",
      "\n",
      "Summarize this article:\n",
      "\n",
      "#Person1#: Adam, could you show me around the school? \n",
      "#Person2#: No problem. \n",
      "#Person1#: What's the tallest building? \n",
      "#Person2#: You mean the white building near the playground? \n",
      "#Person1#: Yes. \n",
      "#Person2#: That is the library. And it has more than 1, 000, 000 books. \n",
      "#Person1#: What's the building to the south of the library? \n",
      "#Person2#: You know, our school is divided into two parts, the junior high school and the senior high school. That is the new classroom building for our senior high school. \n",
      "#Person1#: Is there a swimming pool in your school? \n",
      "#Person2#: Yes. There is a large swimming pool, but it is only available in summer. \n",
      "#Person1#: I do envy you. And I hope I can enter your school one day. \n",
      "#Person2#: I believe that you can make your dream come true. \n",
      "\n",
      "Summary:\n",
      "#Person1# asks Adam to show #Person1# around the school. #Person1# envies Adam and hopes to enter Adam's school one day.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: \n",
    "idxs = [ 10, 20, 30, 40 ]\n",
    "prompt = mk_examplars(dataset['validation'], idxs)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize this article:\n",
      "\n",
      "#Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "\n",
      "Summary:\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "dialogue = dataset['test'][i]['dialogue']\n",
    "our_prompt = f\"Summarize this article:\\n\\n{dialogue}\\n\\nSummary:\"\n",
    "\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize this article:\n",
      "\n",
      "#Person1#: I am tired of everything in my life.\n",
      "#Person2#: What? How happy you life is! I do envy you.\n",
      "#Person1#: You don't know that I have been over-protected by my mother these years. I am really about to leave the family and spread my wings.\n",
      "#Person2#: Maybe you are right.\n",
      "\n",
      "Summary:\n",
      "#Person1# feels tired because of #Person1#'s mother's over-protection.\n",
      "\n",
      "\n",
      "Summarize this article:\n",
      "\n",
      "#Person1#: Did you know that drinking beer helps you sing better?\n",
      "#Person2#: Are you sure? How do you know?\n",
      "#Person1#: Well, usually people think I'm a terrible singer, but after we all have a few beers, they say I sound a lot better!\n",
      "#Person2#: Well, I heard that if you drink enough beer, you can speak foreign languages better. . .\n",
      "#Person1#: Then after a few beers, you'll be singing in Taiwanese?\n",
      "#Person2#: Maybe. . .\n",
      "\n",
      "Summary:\n",
      "#Person1# says drinking beer helps sing better, but #Person2# heard it helps speaking foreign languages.\n",
      "\n",
      "\n",
      "Summarize this article:\n",
      "\n",
      "#Person1#: We've been cramming for tomorrow's history exam since early this morning. What do you say we take a break and listen to some music, okay?\n",
      "#Person2#: Now that you mention it, I'm getting a little bumed-out from studying nonstop, too. Listening to some music for a while would suit me just fine.\n",
      "#Person1#: While you're picking out a record to play, I'll grab a couple of beers out of the refrigerator.\n",
      "#Person2#: You sure have a lot of discs here.\n",
      "#Person1#: Yeah, I've got everything from rock n'roll to the latest new - wave stuff.\n",
      "#Person2#: To tell you the truth, I'm strictly into classical music. You don't happen to have any Bach or Mozart, do you?\n",
      "#Person1#: Sorry, my taste in music doesn't go back any further than the 1960's. Music written before then is just history to me.\n",
      "#Person2#: Well, speaking of history, let's get back to the books. We'Ve got an exam tomorrow, remember?\n",
      "\n",
      "Summary:\n",
      "#Person1# and #Person2# are preparing for the history exam. #Person1# suggests taking a break to listen to some music, but they have different music tastes. Then they get back to books.\n",
      "\n",
      "\n",
      "Summarize this article:\n",
      "\n",
      "#Person1#: Adam, could you show me around the school? \n",
      "#Person2#: No problem. \n",
      "#Person1#: What's the tallest building? \n",
      "#Person2#: You mean the white building near the playground? \n",
      "#Person1#: Yes. \n",
      "#Person2#: That is the library. And it has more than 1, 000, 000 books. \n",
      "#Person1#: What's the building to the south of the library? \n",
      "#Person2#: You know, our school is divided into two parts, the junior high school and the senior high school. That is the new classroom building for our senior high school. \n",
      "#Person1#: Is there a swimming pool in your school? \n",
      "#Person2#: Yes. There is a large swimming pool, but it is only available in summer. \n",
      "#Person1#: I do envy you. And I hope I can enter your school one day. \n",
      "#Person2#: I believe that you can make your dream come true. \n",
      "\n",
      "Summary:\n",
      "#Person1# asks Adam to show #Person1# around the school. #Person1# envies Adam and hopes to enter Adam's school one day.\n",
      "\n",
      "\n",
      "Summarize this article:\n",
      "\n",
      "#Person1#: Happy Birthday, this is for you, Brian.\n",
      "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
      "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
      "#Person2#: Ok.\n",
      "#Person1#: This is really wonderful party.\n",
      "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
      "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
      "#Person2#: You look great, you are absolutely glowing.\n",
      "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
      "\n",
      "Summary:\n"
     ]
    }
   ],
   "source": [
    "final_prompt = prompt + our_prompt\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "#Person1#: Happy Birthday, Brian. #Person2#: I'm so happy you remember. #Person1#: This is really wonderful party. #Person2#: You look very pretty today. #Person1#: Thanks, that's very kind of you to say. #Person2#: You look great, you are absolutely glowing. #Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday.\n"
     ]
    }
   ],
   "source": [
    "enc_final_prompt = tokenizer(final_prompt, return_tensors='pt')\n",
    "compl = model.generate(enc_final_prompt['input_ids'], max_new_tokens=500)\n",
    "dec_compl = tokenizer.decode(compl[0], skip_special_tokens=True)\n",
    "\n",
    "original_summary = dialogue = dataset['test'][i]['summary']\n",
    "\n",
    "print(original_summary)\n",
    "\n",
    "print(dec_compl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Happy Birthday, Brian. #Person2#: I'm so happy you remember. #Person1#: This is really wonderful party. #Person2#: You look very pretty today. #Person1#: Thanks, that's very kind of you to say. #Person2#: You look great, you are absolutely glowing. #Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday.\n"
     ]
    }
   ],
   "source": [
    "enc_our_prompt = tokenizer(our_prompt, return_tensors='pt')\n",
    "compl_zero = model.generate(enc_our_prompt['input_ids'], max_new_tokens=500)\n",
    "dec_compl_zero = tokenizer.decode(compl_zero[0], skip_special_tokens=True)\n",
    "\n",
    "print(dec_compl_zero)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
